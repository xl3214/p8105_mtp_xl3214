---
title: "NYC Zip Code Level Population Changes"
output: 
  prettydoc::html_pretty:
    theme: leonids
    css: styles.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r library necessary R packages, message = FALSE, echo = FALSE}
library(tidyr)
library(readxl)
library(dplyr)
library(janitor)
library(lubridate)
library(ggplot2)
```

## Project Overview
```{r Import data, message = FALSE, echo = FALSE, results = 'hide'}
file_path <- "USPS CHANGE OF ADDRESS NYC.xlsx"
sheet_names <- excel_sheets(file_path)
data_frames <- lapply(sheet_names, function(sheet_name) {
  read_excel(file_path, sheet = sheet_name)
})

coa <- bind_rows(data_frames)
zip <- read.csv("Zip Codes.csv")
summary(coa)
summary(zip)
```

This project examines NYC ZIP code-level population changes using USPS Change of Address (COA) data. Raw data are imported from [HERE](https://p8105.com/data/USPS%20CHANGE%20OF%20ADDRESS%20NYC.xlsx). Since COA may not accurately reflect NYCâ€™s counties, boroughs, and neighborhoods, a supplementary Zip Codes (ZIP) dataset is imported from [HERE](https://p8105.com/data/Zip%20Codes.csv). I cleaned, merged, and performed exploratory analysis to identify population shifts, investigate data quality, and reveal demographic trends while addressing dataset limitations. The raw COA dataset contains `r ncol(coa)` variables and `r nrow(coa)` observations, while the raw Zip Codes dataset includes `r ncol(zip)` variables and `r nrow(zip)` observations. For this project, I utilized R version 4.3.1, and R packages `tidyr`, `readxl`, `dplyr`, `janitor`, `lubridate`, and `ggplot2`. 

## Data Wrangling

```{r Clean and Tidy and Combine the Datasets, results='hide', message=FALSE, warning=FALSE, echo=FALSE}
# Define file paths and read data from Excel and CSV files
file_path <- "USPS CHANGE OF ADDRESS NYC.xlsx"
sheet_names <- excel_sheets(file_path)
data_frames <- lapply(sheet_names, function(sheet_name) {
  read_excel(file_path, sheet = sheet_name)
})

# Combine COA data, clean column names, and create new columns
coa <- bind_rows(data_frames) |>
  clean_names() |>
  rename(zip_code = zipcode) |>
  mutate(year = year(month)) |>
  mutate(net_change = total_perm_in - total_perm_out)

# Read ZIP code data from CSV, clean column names, and add a 'borough' variable
zip <- read.csv("Zip Codes.csv") |> 
  janitor::clean_names() |> 
  mutate(borough = county_name)

# Compare COA and ZIP data using joins
test1 <- anti_join(coa, zip, by = "zip_code") # 0 observations of 7 variables
test2 <- left_join(coa, zip, by = "zip_code") # 12085 observations of 14 variables
test3 <- right_join(coa, zip, by = "zip_code") # 12168 observations of 14 variables
test4 <- inner_join(coa, zip, by = "zip_code") # 12085 observations of 14 variables
test5 <- full_join(coa, zip, by = "zip_code") # 12168 observations of 14 variables

# Proceed with left_join to include only COA records in the final dataset
rm(test1, test2, test3, test4, test5)

# Merge COA and ZIP data, address many-to-many relationship warning
tidy <- left_join(coa, zip, by = "zip_code")
# Warning: Detected an unexpected many-to-many relationship between `x` and `y`.
# Need to go back and edit the codes to keep a one-to-many relationship between COA and ZIP.

# Check for duplicated combinations of month and zip_code in COA dataset
coa_duplicated <- coa |>
  group_by(month, zip_code) |>
  filter(duplicated(month, zip_code))
print(coa_duplicated)
# No duplicated combinations of month and zip_code in COA dataset.

# Check for duplicated combinations of zip_code and neighborhood in ZIP dataset
zip_duplicated <- zip |>
  group_by(zip_code, neighborhood) |>
  filter(duplicated(zip_code, neighborhood))
print(zip_duplicated)
# Four duplicated combinations of zip_code and neighborhood in COA dataset: 10463, 11201, 11239, 11693
zip |> filter(zip_code %in% c(10463, 11201, 11239, 11693))

# Update 'borough' variable to fix duplicates
unique(pull(zip, county_name))
zip <- zip |> 
  mutate(borough = ifelse(county_name == "Kings", "Brooklyn",
                          ifelse(county_name == "Richmond", "Staten Island",
                                 ifelse(county_name == "New York", "Manhattan", borough))))
unique(pull(zip, borough))

# Fix duplicates of zip codes 10463, 11201, 11239, and 11693
zip <- zip |> 
  mutate(
    county_name = case_when(
      zip_code == 10463 ~ "Bronx", # Code 10463 as Bronx county
      zip_code %in% c(11201, 11239) ~ "Kings", # Code 11201 and 11239 as Kings county
      zip_code == 11693 ~ "Queens", # Code 11693 as Queens county
      TRUE ~ county_name),  # Leave other rows as they are
    borough = case_when(
      zip_code %in% c(11201, 11239) ~ "Brooklyn",
      TRUE ~ borough))  # Leave other rows as they are

# Delete duplicates based on zip_code
zip <- zip |>
  distinct(zip_code, .keep_all = TRUE)
# Checking for duplicates one last time
zip |> filter(zip_code %in% c(10463, 11201, 11239, 11693))

# Merge COA and ZIP data
tidy <- left_join(coa, zip, by = "zip_code")

summary(tidy)

# List of objects to keep
objects_to_keep <- c("coa", "zip", "tidy")

# Get a list of all objects in the current environment
all_objects <- ls()

# Find objects to remove
objects_to_remove <- setdiff(all_objects, objects_to_keep)

# Remove objects to be deleted
rm(list = objects_to_remove)
rm(objects_to_remove, all_objects)

# Keep only variables needed for further analysis
tidy <- tidy |> 
  select(year, month, city, borough, county_name, neighborhood, total_perm_out, total_perm_in, net_change, zip_code) |> 
  mutate(zip_code = as.character(zip_code))
```

Data preparation involved importing files and combining sheets in COA. Column names were cleaned, and new variables (`year` and `net_change` in COA, `borough` in ZIP) were created. Various joining methods were compared for data consistency. A `left_join` merged COA and ZIP, warning many-to-many relationships. Checks were conducted for duplicates in COA and ZIP. `borough` names were updated, and duplicates for specific zip codes were addressed. 

The final tidy dataset has `r ncol(tidy)` columns and `r nrow(tidy)` rows. 

### Variables and examples: 

* ``r colnames(tidy[,1])`` (`r class(pull(tidy, var = 1))`): `r head(unique(pull(tidy, var = 1)))`.
* ``r colnames(tidy[,2])`` (`r class(pull(tidy, var = 2))`): `r head(unique(pull(tidy, var = 2)))`.
* ``r colnames(tidy[,3])`` (`r class(pull(tidy, var = 3))`): `r head(unique(pull(tidy, var = 3)))`. There are `r length(unique(pull(tidy, var = 3)))` unique entries.
* ``r colnames(tidy[,4])`` (`r class(pull(tidy, var = 4))`): `r head(unique(pull(tidy, var = 4)))`. There are `r length(unique(pull(tidy, var = 4)))` unique entries.
* ``r colnames(tidy[,5])`` (`r class(pull(tidy, var = 5))`): `r head(unique(pull(tidy, var = 5)))`. There are `r length(unique(pull(tidy, var = 5)))` unique entries.
* ``r colnames(tidy[,6])`` (`r class(pull(tidy, var = 6))`): `r head(unique(pull(tidy, var = 6)))`. There are `r length(unique(pull(tidy, var = 6)))` unique entries. Additionally, there are `r sum(is.na(tidy[, 6]))` missing entries in this variable.
* ``r colnames(tidy[,7])`` (`r class(pull(tidy, var = 7))`): range `r min(pull(tidy, var = 7))` to `r max(pull(tidy, var = 7))`, mean = `r mean(pull(tidy, var = 7))`.
* ``r colnames(tidy[,8])`` (`r class(pull(tidy, var = 8))`): range `r min(pull(tidy, var = 8))` to `r max(pull(tidy, var = 8))`, mean = `r mean(pull(tidy, var = 8))`.
* ``r colnames(tidy[,9])`` (`r class(pull(tidy, var = 9))`): range `r min(pull(tidy, var = 9))` to `r max(pull(tidy, var = 9))`, mean = `r mean(pull(tidy, var = 9))`.
* ``r colnames(tidy[,10])`` (`r class(pull(tidy, var = 10))`): `r head(unique(pull(tidy, var = 10)))`. There are `r length(unique(pull(tidy, var = 10)))` unique entries.

### Data Quality Assessment

#### Table Comparing 'city' to 'borough'
```{r Cross comparison of city and borough variables, message=FALSE, warning=FALSE, echo=FALSE}
# Compare 'city' to 'borough'
comparison_result <- tidy |>
  group_by(borough, city) |>
  summarise(count = n()) |> 
  pivot_wider(names_from = "city", values_from = "count")

# Head the comparison result
comparison_result |> knitr::kable()
```

The table above (`r nrow(comparison_result)` observations) reveals data quality issues: 'New York' mismatched with both 'Manhattan' and 'Brooklyn,' indicating inconsistent city-to-borough relationships. 'ROOSEVELT ISLAND' appearing as 'ROOSEVELT ISL' in the manhattan_table suggests data transformation problems. Variations like 'QUEENS VILLAGE' and 'QUEENS VILLAGE, QUEENS' point to city name inconsistencies. 'BOWLING GREEN' and 'CANAL STREET' in the 'city' variable may signal data entry errors. 

#### top 5 most common cities in Manhattan borough
```{r Manhattan Tables, message=FALSE, warning=FALSE, echo=FALSE}
# Filter the tidy dataset for Manhattan and Queens boroughs
manhattan_data <- tidy |>
  filter(borough == "Manhattan")
queens_data <- tidy |>
  filter(borough == "Queens")

# Create tables for the most common values of "city" in Manhattan
manhattan_table <- manhattan_data |>
  count(city, sort = TRUE) |>
  head(5) # Showing top 5 common cities in Manhattan borough
manhattan_table |> knitr::kable()
```

#### top 5 most common cities in Queens borough
```{r Queens Tables, message=FALSE, warning=FALSE, echo=FALSE}
queens_table <- queens_data |>
  count(city, sort = TRUE) |>
  head(5) # Showing top 5 common cities in Queens borough
queens_table |> knitr::kable()
```

Tables above reaffirmed data quality issues mentioned earlier. 

```{r Data Quality Checking, message=FALSE, warning=FALSE, results='hide', echo=FALSE}
# Check for ZIP codes with <60 observations
le60 <- tidy |> 
  group_by(zip_code) |>
  summarize(n_obs = n()) |> 
  filter(n_obs < 60)

# Check for NAs in 'neighborhood' in both ZIP and tidy datasets
zip_na <- zip |> filter(is.na(neighborhood)) # 142 NAs in neighborhood variable in ZIP dataset
tidy_na <- tidy |> filter(is.na(neighborhood)) # 1288 NAs in neighborhood variable in tidy dataset
```

There are `r count(le60)` ZIP codes with less than 60 observations, and `r count(tidy_na)` observations with missing neighborhood data, indicating potential data gaps due to factors like sparse data collection, inconsistent reporting, demographic variations, and data source limitations.

## EDA and Visualization

#### Average Net Change Table, by year and borough
```{r Summary Table, message=FALSE, warning=FALSE, echo=FALSE}
# Group and summarize data to calculate the average net_change by year and borough
avg_net_change_table <- tidy |>
  group_by(borough, year) |>
  summarize(avg_net_change = mean(net_change, na.rm = TRUE)) |>
  pivot_wider(names_from = "year", values_from = "avg_net_change")

# View the resulting table
avg_net_change_table |> knitr::kable()
```

The table reveals trends in average net change by borough and year. Annual fluctuations, particularly significant decreases in 2020, are observed. Brooklyn consistently exhibits the highest negative average net change, contrasting with Staten Island's stability. The Bronx and Queens display varying average net change, reflecting population fluctuations, possibly influenced by the COVID-19 pandemic in 2020. These trends may stem from demographic shifts and housing patterns.

#### Five lowest values of net change across all observed data
```{r Table showing five lowest values of net_change across all observed data, message=FALSE, warning=FALSE, echo=FALSE}
# Five lowest values of net_change across all observed data
lowest_net_change_all <- tidy |>
  arrange(net_change) |>
  mutate(month = month(month)) |>
  select(zip_code, neighborhood, year, month, net_change) |>
  head(5)

# Display the resulting tables
lowest_net_change_all |> knitr::kable()
```

#### Five highest values of net change before 2020
```{r Table showing five highest values of net_change before 2020, message=FALSE, warning=FALSE, echo=FALSE}
# Five highest values of net_change before 2020
highest_net_change_before_2020 <- tidy |>
  filter(year < 2020) |>
  arrange(desc(net_change)) |>
  mutate(month = month(month)) |>
  select(zip_code, neighborhood, year, month, net_change) |>
  head(5)

# Display the resulting tables
highest_net_change_before_2020 |> knitr::kable()
```

#### Trend plot of neighborhood-level average net change by month
```{r Visualizations, message=FALSE, warning=FALSE, echo=FALSE}
# Calculate neighborhood-level average net_change by month
neighborhood_avg <- tidy |>
  group_by(borough, neighborhood, year, month) |>
  summarize(avg_net_change = mean(net_change))

# Create a line plot to visualize the trends
neighborhood_avg |>
  ggplot(aes(x = month, y = avg_net_change, color = borough, group = borough)) +
  geom_point(alpha = 0.15) +
  geom_smooth(se = FALSE) + 
  labs(title = "Neighborhood-Level Average Net Change Over 5 Years",
       x = "Month", y = "Average Net Change", color = "Borough") +
  theme_minimal() +
  theme_light() + 
  theme(legend.position = "bottom")

ggsave("results/neighborhood_avg_net_change_scatter_line_plot.png", width = 8, height = 4)
```

Neighborhood-Level average net change is mostly below zero across all boroughs, over 5 years. The mean net change is `r mean(pull(tidy, net_change))`. Overall, Manhattan has the lowest average net change, Staten Island has the highest. Average net change is stable in 2018, 2019, and 2022. However, a substantial drop occurred between 2020 and 2021, especially in Manhattan.

## Limitations

The dataset has many limitations, including data quality issues, borough mismatches, many-to-many relationships, limited time range, local influences, and potential seasonal patterns. It lacks demographic and socioeconomic data. Thorough preprocessing and data integration are needed for a holistic view of population changes.

```{r Word Count, message=FALSE, warning=FALSE, echo=FALSE}
wordcountaddin::text_stats("p8105_mtp_xl3214.Rmd")
```

